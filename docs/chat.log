LookFlex 의사결정 로그
프로젝트 진행 과정에서 내려진 주요 결정들을 시간순으로 기록합니다.

================================================================================
[2026-02-28] 프로젝트 기획 및 기술 스택 선정
================================================================================

배경
----
Google Looker Studio를 사내 BI 대시보드로 사용 중이었으나 다음 문제로 대체 결정:

  - 그리드 간격이 넓어 테이블 배치 위치 조정이 어려움
  - Viewer 권한 사용자가 메트릭을 바꾸려면 헤더의 작은 아이콘을 찾아 클릭해야 하는
    비직관적인 UX
  - 조건부 서식을 열 단위로 마우스 UI를 통해 하나씩 설정해야 하는 비효율

Grafana 등 오픈소스 플랫폼도 검토했으나, 실시간 시계열보다 테이블 데이터 위주이고
ETL은 배치 처리 방식이라 범용 오픈소스보다 직접 구축이 더 적합하다고 판단.

결정된 기술 스택
----------------
프론트엔드:
  - Next.js 14+ (App Router) + TypeScript
  - TanStack Table v8 — 조건부 서식·컬럼 커스터마이징을 코드 레벨에서 완전 제어
  - Apache ECharts (echarts-for-react)
  - TanStack Query, Zustand, Tailwind CSS + shadcn/ui

백엔드:
  - FastAPI (Python 3.11+)
  - SQLAlchemy 2.0 (async) + Alembic
  - JWT 인증 (python-jose + passlib/bcrypt)

데이터베이스 / 인프라:
  - PostgreSQL 16 (주 DB — 사용자 계정, 대시보드 설정)
  - Redis 7 (캐시)
  - Docker + Docker Compose
  - Nginx (리버스 프록시)

주요 설계 결정
--------------
  - 사용자별 커스터마이징 설정(메트릭 선택, 조건부 서식, 컬럼 너비 등)은
    PostgreSQL JSONB 컬럼으로 저장
  - 역할: Admin / Editor / Viewer 3단계 분리
  - Access Token(메모리) + Refresh Token(HttpOnly Cookie) 방식
  - 로컬 서버 우선, Docker Compose 기반으로 향후 클라우드 이전 용이하게 설계

================================================================================
[2026-02-28] 백엔드 서버 선택 — FastAPI vs NestJS vs Spring Boot
================================================================================

검토 배경
---------
  - 차트(JavaScript) 구현이 중요한데, Python 백엔드로 괜찮은지 확인 필요
  - BigQuery + PostgreSQL 연동, 향후 다양한 DB 지원(SaaS 확장) 고려
  - Text2SQL 등 AI 기능 추가 가능성 검토
  - Node.js 기반 NestJS나 Java 기반 Spring Boot와의 비교 요청

핵심 전제
---------
차트 렌더링은 백엔드와 무관하다. ECharts 등 차트 라이브러리는 브라우저에서 동작하고,
백엔드는 JSON 데이터를 내려주기만 한다. 백엔드 언어와 무관하게 Next.js에서 모든 차트
구현이 가능하다.

비교 결과
---------
  항목                    FastAPI              NestJS           Spring Boot
  BigQuery 연동          ★★★ Python SDK      ★★☆             ★★☆ JDBC
  다중 DB 지원           ★★☆ SQLAlchemy      ★★☆             ★★★ 네이티브 JDBC
  Text2SQL / AI 연동     ★★★ LangChain 등    ★☆☆ 별도 필요   ★☆☆ 별도 필요
  데이터 처리(pandas 등) ★★★                 ★☆☆             ★☆☆
  개발 속도              ★★★ OpenAPI 자동    ★★★             ★★☆ 보일러플레이트
  SaaS 대규모 확장       ★★☆                 ★★☆             ★★★ 엔터프라이즈

JDBC 관련: Python(SQLAlchemy)도 PostgreSQL·MySQL·MSSQL·Oracle·Snowflake 등 주요 DB를
자체 드라이버로 커버한다. 순수 JDBC 드라이버만 존재하는 레거시 JVM DB 연결이 필요한
경우만 Spring이 유리하다.

NestJS/Spring에서 AI 기능을 원하면 결국 Python 서비스를 별도로 띄워야 하므로 스택이
복잡해진다.

결정: FastAPI 유지
------------------
현재 요구사항(BigQuery + PostgreSQL)과 미래 요구사항(Text2SQL, AI 기능, 다중 DB SaaS)
모두에서 Python 생태계가 가장 직접적으로 대응한다.

재검토 조건: SaaS로 확장 시 수천 명 동시 사용자, 멀티테넌시, 복잡한 트랜잭션 관리가
필요해지는 시점에 Spring Boot 기반 비즈니스 로직 서버 분리를 검토한다.

================================================================================
[2026-02-28] API 문서 작성 (api.md)
================================================================================

작업 내용
---------
api-plan.md의 기능 기획을 바탕으로 바이브 코딩용 REST API 명세서 api.md를 작성했다.

문서 구조
---------
  베이스 URL: http://localhost:8000/api/v1
  공통 응답 envelope {success, data, error}, 페이지네이션 구조, 전체 Enum 정의 포함
  총 13개 도메인, 약 60개 엔드포인트

  1.  Auth                회원가입, 이메일 인증, 로그인, JWT 갱신, 로그아웃, 비밀번호 재설정
  2.  Users               프로필, 비밀번호 변경, 관리자 역할/그룹 일괄 변경
  3.  Groups              DEPARTMENT/POSITION/CUSTOM 그룹 CRUD
  4.  Dashboards & Pages  대시보드/페이지 CRUD, 즐겨찾기, 순서 변경, 복제
  5.  Data Sources        DB 연결, 파일 업로드, 연결 테스트, 스키마 동기화, 권한, 미리보기
  6.  Charts              CRUD, 스타일, 위치 일괄 저장, 차트 그룹, 데이터 조회, XLSX/CSV 내보내기
  7.  Filters             DROPDOWN/TEXT_INPUT/RANGE/DATE_RANGE, 기본 필터 고정
  8.  Cond. Formatting    CRUD, 우선순위 변경, 다른 차트로 복사
  9.  User View Configs   사용자별 메트릭/정렬/컬럼 너비 개인 설정 (Viewer 포함 전 역할)
  10. Number Formats      사전 정의 포맷 목록
  11. Notifications       목록 조회, 읽음 처리
  12. SMTP Admin          이메일 서버 설정/테스트
  13. System              헬스체크, 감사 로그

api-plan.md 대비 추가된 항목
-----------------------------
  - 비밀번호 재설정 플로우 (이메일 발송 → 토큰 검증 → 변경)
  - 데이터소스 연결 테스트, 스키마 동기화, 데이터 미리보기
  - 차트 XLSX/CSV 내보내기
  - 사용자별 뷰 설정 (User View Configs)
  - SMTP 관리자 설정
  - 감사 로그 (Audit Log)

================================================================================
[2026-02-28] 인프라 아키텍처 설계 (infra.md)
================================================================================

작업 내용
---------
프로젝트 폴더 구조, Docker 전략, DB 초기화, Redis 구성, Git 브랜치 전략을 포괄하는
infra.md를 작성했다. (구 architecture.md)

주요 결정 사항
--------------
모노레포 구조 채택:
  - Turborepo/Nx 미사용 — 프론트(npm), 백엔드(pip) 패키지 매니저 독립 유지
  - 하나의 PR로 프론트·백엔드·인프라 변경을 함께 추적

Docker Compose 채택 (minikube/K8s 대신):
  - 100명 미만 규모에서 K8s는 오버엔지니어링
  - kompose convert로 향후 K8s 마이그레이션 가능
  - 전환 검토 시점: SaaS 전환 및 수백 명 이상 동시 사용자, 무중단 배포 요건 발생 시

DB 초기화 2단계 전략:
  - 1단계: infra/postgres/init/*.sql — PostgreSQL 확장 활성화 (uuid-ossp, pgcrypto,
    pg_trgm), 볼륨 최초 생성 시 1회 실행
  - 2단계: Alembic upgrade head — 백엔드 컨테이너 시작 시마다 실행, 테이블 스키마 관리

Redis 역할 정의:
  - OTP 코드 (10분), 비밀번호 재설정 토큰 (1시간), JWT 블랙리스트,
    쿼리 결과 캐시 (5~30분), 알림 카운터
  - maxmemory-policy allkeys-lru, 영속성 비활성화 (재시작 시 유실 허용)
  - Redis 비밀번호는 환경변수 주입이 어려워 redis.conf 파일로 관리

Git 브랜치 전략 — GitHub Flow:
  - 영구 브랜치: main (운영), dev (개발 통합)
  - 작업 브랜치: feature/*, fix/*, hotfix/*, chore/*
  - 네이밍: feature/{도메인}-{요약} (예: feature/auth-register-flow)
  - hotfix/*는 main과 dev 모두 병합
  - Conventional Commits 형식, Semantic Versioning 태그 (main 병합 시)
  - 브랜치는 서비스별(백엔드/프론트)이 아닌 도메인 기준으로 분기

문서 파일명 표준 결정:
  - 루트 특수 파일: UPPERCASE (GitHub 자동 인식 — README.md, LICENSE)
  - docs/ 내 일반 문서: lowercase-kebab-case, 확장자 자유
  - architecture.md → infra.md (내용이 인프라/배포 중심)
  - 문서는 docs/ 폴더에서 일괄 관리, README.md·LICENSE는 루트 유지

================================================================================
[2026-02-28] 프로젝트 초기 스캐폴딩 구현 (chore: initial project scaffold)
================================================================================

작업 내용
---------
infra.md 설계를 바탕으로 전체 프로젝트 뼈대를 생성했다.
Git 커밋 규칙: 커밋 생성 직전에 chat.log에 작업 내역을 먼저 기록한다.

생성된 파일 목록 (총 39개)
---------------------------
루트 설정:
  - .gitignore         — Python/Node.js/env 파일 제외, docs/chat.log 명시적 언트래킹 방지
  - .env.example       — 전체 환경변수 목록 (빈값 + 주석)
  - Makefile           — dev, dev-down, prod, prod-down, migrate, makemigration, logs, ps

Docker Compose:
  - docker-compose.yml      — 기본 서비스 정의 (postgres, redis, backend, frontend, nginx)
  - docker-compose.dev.yml  — 개발 오버라이드 (포트 노출, 볼륨 마운트, 핫리로드)
  - docker-compose.prod.yml — 운영 오버라이드 (443포트, 리소스 제한, json-file 로깅)

인프라 설정:
  - infra/nginx/nginx.conf          — Nginx 베이스 설정, client_max_body_size 50M
  - infra/nginx/conf.d/local.conf   — HTTP 프록시 (API → backend:8000, / → frontend:3000)
  - infra/nginx/conf.d/prod.conf    — HTTPS 템플릿 (certbot 적용 전 주석 처리)
  - infra/nginx/Dockerfile          — FROM nginx:1.27-alpine
  - infra/postgres/init/00_create_extensions.sql — uuid-ossp, pgcrypto, pg_trgm 확장
  - infra/redis/redis.conf          — requirepass, maxmemory 256mb, allkeys-lru, 영속성 비활성화

백엔드 골격 (apps/backend/):
  - Dockerfile           — 멀티스테이지 운영 빌드 (builder → runner)
  - Dockerfile.dev       — uvicorn --reload 개발용
  - pyproject.toml       — 전체 의존성 (fastapi, sqlalchemy[asyncio], alembic, jwt, redis 등)
  - alembic.ini          — Alembic 기본 설정
  - entrypoint.sh        — alembic upgrade head 후 gunicorn 실행
  - app/main.py          — FastAPI 앱, CORS 미들웨어, /api/v1/health 엔드포인트
  - app/core/config.py   — Pydantic BaseSettings, 전체 환경변수 매핑
  - app/db/base.py       — SQLAlchemy DeclarativeBase
  - app/db/session.py    — AsyncSession 팩토리, get_db 의존성
  - alembic/env.py       — 비동기 Alembic env, settings 연동
  - alembic/script.py.mako — 마이그레이션 파일 템플릿
  - alembic/versions/.gitkeep
  - app/api/__init__.py, app/core/__init__.py, app/db/__init__.py
  - app/db/models/__init__.py, app/schemas/__init__.py
  - app/services/__init__.py, app/repositories/__init__.py
  - tests/__init__.py

커밋 규칙 추가
--------------
앞으로 Git 커밋 생성 직전에 chat.log에 해당 커밋의 작업 내역을 먼저 기록한다.

완료 후 상태
------------
  - main 브랜치에 root commit 1개 (a6f069c)
  - dev 브랜치 생성 및 origin push 완료 (main, dev 모두)
  - git push 완료

다음 단계 (예정)
----------------
  1. feature/backend-models 브랜치에서 SQLAlchemy 모델 작성  ← 진행 예정
  2. Alembic 초기 마이그레이션 생성
  3. apps/frontend/ Next.js 스캐폴딩

================================================================================
[2026-02-28] SQLAlchemy 모델 및 Alembic 초기 마이그레이션
            (feat: add SQLAlchemy models and initial Alembic migration)
================================================================================

작업 내용
---------
api.md의 13개 도메인 전체를 커버하는 SQLAlchemy 2.0 async 모델을 작성하고
Alembic 초기 마이그레이션 파일을 수동으로 생성했다.
브랜치: feature/backend-models (dev 기준)

생성된 파일 (apps/backend/app/db/models/)
------------------------------------------
  enums.py        — 프로젝트 전체 Enum 정의 (12종)
                    Role, ApprovalStatus, GroupType, DSSourceType, FieldType,
                    AggregateType, ChartType, FilterType, FilterOp, SortDir,
                    CondFormatApplyTo, NotificationType, AuditAction

  user.py         — User, Group, RegisterRequest + user_group M2M 연결 테이블
                    User.role (OWNER/ADMIN/EDITOR/VIEWER), is_active, email_verified_at
                    RegisterRequest: 이메일 인증 → 관리자 승인 대기 플로우용

  dashboard.py    — Dashboard, Page, DashboardFavorite, PageFavorite
                    Page.dashboard_id nullable (독립 페이지 허용)
                    Page: x/y/width/height px 단위 캔버스, background_color

  datasource.py   — DataSource, DataSourceField, DataSourcePermission
                    connection_config: JSONB (암호화는 서비스 레이어에서 처리)
                    allow_all 플래그 + entity_type/entity_id 조합으로 Fine-grained 권한 관리

  chart.py        — Chart, ChartGroup, ChartGroupItem
                    Chart.config JSONB: 차트 타입별 설정 (dimensions, metrics 등)
                    Chart.style JSONB: 헤더/바디/합계행 스타일
                    ChartGroup: 여러 차트를 묶어 이동/크기조정 연동

  filter.py       — Filter, DefaultFilterRule
                    Filter: 페이지에 배치되는 인터랙티브 UI 요소
                    DefaultFilterRule.apply_to: "PAGE" 또는 chart_id 문자열

  formatting.py   — ConditionalFormat, ConditionalFormatRule
                    ConditionalFormat.order: 서식 평가 순서 (낮을수록 우선)
                    ConditionalFormatRule.style JSONB: backgroundColor, color, fontWeight 등

  view_config.py  — UserViewConfig
                    user_id + chart_id UNIQUE 제약 (사용자별 1개)
                    config JSONB: metrics, sort, columnWidths, frozenColumns, rowsPerPage

  notification.py — Notification
                    is_read, created_at 인덱스 포함

  system.py       — SmtpConfig (싱글턴 id=1), AuditLog
                    AuditLog.detail JSONB: 액션별 상세 (chartId, datasourceId 등)

  __init__.py     — 모든 모델 import (Alembic autogenerate 인식용)

생성된 마이그레이션 파일
------------------------
  alembic/versions/a1b2c3d4e5f6_initial_schema.py
    - Revision: a1b2c3d4e5f6, down_revision: None (root)
    - upgrade(): PostgreSQL Enum 타입 12종 생성 후 테이블 22개 생성
    - downgrade(): 역순 삭제 (FK 의존성 고려)
    - 수동 작성 (DB 연결 없이 생성, 컨테이너 첫 기동 시 자동 적용)

테이블 목록 (22개)
-------------------
  audit_logs, chart_group_items, chart_groups, charts,
  conditional_format_rules, conditional_formats,
  dashboard_favorites, dashboards,
  datasource_fields, datasource_permissions, datasources,
  default_filter_rules, filters, groups, notifications,
  page_favorites, pages, register_requests,
  smtp_configs, user_group, user_view_configs, users

검증 방법
---------
  conda run -n main python -c "from app.db.models import *; ..."
  → 22개 테이블 정상 등록 확인 (SQLAlchemy 2.0 업그레이드 필요: pip install sqlalchemy>=2.0)
  → alembic/versions/*.py AST 파싱 오류 없음

설계 결정 사항
--------------
  JSONB 사용 필드:
    - DataSource.connection_config — DB 연결 정보 (암호화 후 저장 예정)
    - Chart.config / style — 차트 타입별 설정/스타일 자유도 확보
    - Filter.config — 필터 타입별 설정
    - ConditionalFormatRule.value / second_value — 숫자·문자·null 통합 수용
    - UserViewConfig.config — 사용자 개인 뷰 오버라이드 전체
    - AuditLog.detail — 액션별 부가 정보

  소프트 딜리트 미채택: is_active(User만), 나머지는 CASCADE DELETE
  SmtpConfig: 싱글턴 패턴 (Integer PK id=1), 복수 설정 불필요

다음 단계 (예정)
----------------
  1. PR: feature/backend-models → dev 머지  ← 완료
  2. feature/auth 브랜치에서 Auth API 구현  ← 완료
  3. apps/frontend/ Next.js 스캐폴딩

================================================================================
[2026-02-28] Auth API 구현
            (feat(backend): implement Auth API endpoints)
================================================================================

작업 내용
---------
api.md §1 Auth 전체 10개 엔드포인트를 구현했다.
브랜치: feature/auth (dev 기준)

생성된 파일 목록
----------------
  app/core/security.py
    - hash_password / verify_password (bcrypt via passlib)
    - create_access_token (15분) / create_refresh_token (7일) (JWT via python-jose)
    - decode_token(token, token_type) → user_id 또는 None

  app/core/redis.py
    - aioredis.Redis 모듈 레벨 싱글턴
    - init_redis / close_redis (lifespan 훅에서 호출)
    - 키 네임스페이스 헬퍼: otp_key, pw_reset_key, jwt_blacklist_key

  app/core/deps.py
    - get_current_user: Bearer 토큰 검증 → User 객체 반환
    - CurrentUser: Annotated 타입 앨리어스
    - require_role(*roles): 역할 레벨 비교 의존성 팩토리

  app/schemas/common.py
    - ApiResponse[T]: {success, data, error} envelope
    - PaginatedData[T]: {items, total, page, limit, total_pages}

  app/schemas/auth.py
    - RegisterRequest, RegisterResponse
    - VerifyEmailRequest, ResendCodeRequest, MessageResponse
    - LoginRequest, TokenResponse
    - RegisterRequestItem, ProcessRegisterRequest, ProcessRegisterResponse
    - PasswordResetRequestBody, PasswordResetBody

  app/schemas/user.py
    - UserProfile, GroupSummary

  app/repositories/user_repository.py
    - UserRepository: get_by_id, get_by_email, create, save
    - RegisterRequestRepository: get_by_email_pending, get_by_id,
      create, list_by_status, save

  app/services/email_service.py
    - send_email: SMTP 미설정 시 logger.warning으로 fallback
    - send_otp_email, send_password_reset_email, send_approval_result_email

  app/services/auth_service.py
    - register: 중복 검사 → RegisterRequest 생성 → OTP 발송(Redis TTL 10분)
    - verify_email: OTP 검증 → email_verified_at 기록
    - resend_code: OTP 재생성 및 재발송
    - login: 비밀번호 검증 → AccessToken + RefreshToken 반환
    - refresh: Refresh JWT 검증 → 새 AccessToken 반환
    - list_register_requests: 상태별 페이지네이션 목록 (ADMIN)
    - process_register_request: 승인시 User 생성 / 거절시 reason 저장 (ADMIN)
    - password_reset_request: 재설정 토큰 Redis 저장 (TTL 1시간)
    - password_reset: 토큰 검증 → 비밀번호 변경

  app/api/v1/__init__.py (빈 파일)
  app/api/v1/router.py — api_router (prefix=/api/v1)
  app/api/v1/auth.py — 10개 엔드포인트 (prefix=/auth)
    POST   /auth/register
    POST   /auth/verify-email
    POST   /auth/resend-code
    POST   /auth/login           → RefreshToken HttpOnly 쿠키 Set-Cookie
    POST   /auth/refresh          → 쿠키에서 RefreshToken 읽기
    POST   /auth/logout           → 쿠키 삭제 (204)
    GET    /auth/register-requests  (ADMIN+)
    PATCH  /auth/register-requests/{requestId}  (ADMIN+)
    POST   /auth/password-reset-request
    POST   /auth/password-reset

수정된 파일
-----------
  app/main.py
    - lifespan asynccontextmanager 추가 (init_redis / close_redis)
    - api_router include (app/api/v1/router.py)

설계 결정 사항
--------------
  이메일 발송: asyncio.create_task로 fire-and-forget — SMTP 실패가 API 응답에 영향 없음
  비밀번호 재설정 URL: 프론트엔드 baseURL 하드코딩 (http://localhost:3000)
    → 추후 settings.FRONTEND_URL 환경변수로 교체 예정
  Refresh Token 쿠키 Path: /api/v1/auth/refresh — 다른 엔드포인트에 쿠키 전송 방지
  역할 레벨 비교: OWNER=4, ADMIN=3, EDITOR=2, VIEWER=1
    require_role(Role.ADMIN, Role.OWNER) → ADMIN 이상 허용

검증 방법
---------
  conda run -n main python -c "from app.main import app; ..."
  → All imports OK
  → Auth routes (10개) 정상 등록 확인

다음 단계 (예정)
----------------
  1. PR: feature/auth → dev 머지
  2. feature/users 브랜치에서 Users API 구현
  3. apps/frontend/ Next.js 스캐폴딩
================================================================================
[2026-02-28] Docker 실동작 검증 및 빌드 버그 수정
================================================================================

배경
----
feature/auth 머지 후 "실제 Docker 환경에서 동작하는지 검증" 단계 진행.
docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d postgres redis backend
실행 시 4가지 연쇄 오류가 차례로 드러났다.
각 오류는 이전 오류가 수정되어야 다음 오류가 보이는 구조여서, 총 4회 빌드/재시작을 반복했다.

시행착오 상세
-------------

[오류 1] Docker 빌드 실패 — BackendUnavailable: Cannot import 'setuptools.backends.legacy'

  발생 위치: Dockerfile.dev RUN 단계 (pip install -e ".[dev]")
  원인: pyproject.toml에 build-backend = "setuptools.backends.legacy:build"로 작성했는데
        이 경로는 setuptools에 실제로 존재하지 않는다.
        setuptools 28.x 이하에는 legacy 모듈이 없었고, 최신 setuptools(68+)에서도
        backends.legacy라는 서브패키지 경로는 없다.
        올바른 경로는 "setuptools.build_meta"다.
  수정: build-backend = "setuptools.build_meta"
  부가 수정: Dockerfile.dev의 RUN 명령에서 pip install setuptools>=68이 쉘에서
        >= 68로 해석될 가능성을 막기 위해 따옴표 추가: "setuptools>=68"
        editable install (-e) 시 setuptools가 현재 디렉터리에서 소스를 스캔하는데,
        Dockerfile 빌드 시점에 app/ 소스가 없으므로 mkdir -p app으로 stub 생성.

[오류 2] Alembic 마이그레이션 실패 — DuplicateObjectError: type "role" already exists

  발생 시점: 빌드 성공 후 컨테이너 첫 기동, alembic upgrade head 실행 중
  증상: 처음 실행이었는데 왜 "이미 존재"라는 오류가 날까?
  원인 분석 과정:
    - 첫 기동에서 Alembic이 일부 DDL을 실행하다 오류로 중단
    - DuplicateObjectError 발생 시 트랜잭션이 롤백되지만 alembic_version 테이블에는
      기록이 남지 않아, 컨테이너 재시작마다 동일 마이그레이션을 재시도
    - 재시도할 때 앞선 실행에서 partial하게 생성된 enum 타입이 남아 있어 duplicate 발생
  원인 근본: postgresql.ENUM(...).create(op.get_bind(), checkfirst=True) 패턴이
        asyncpg 환경에서 실제로 checkfirst 쿼리를 실행하지 않는다.
        asyncpg는 sync wrapper (greenlet 기반) 위에서 작동하는데,
        sqlalchemy가 checkfirst를 위해 내부적으로 SELECT가 필요한 시점에
        sync context 밖에서 await을 시도해 오류 없이 무시되거나
        단순히 CREATE TYPE을 실행해버린다.
        결론: checkfirst=True가 asyncpg+alembic 조합에서 신뢰할 수 없다.

  1차 수정 시도 (잘못된 접근):
    op.create_table() 내부의 sa.Enum(...) 컬럼 정의에 create_type=False 추가.
    → 이때 sa.Enum은 create_type 키워드를 받지 않는다는 사실을 몰랐음.
      sa.Enum은 해당 파라미터를 조용히 무시(silently ignore)하므로 효과 없음.
    → 실제로 create_type=False를 이해하는 것은 postgresql.ENUM()이다.

  2차 수정 시도 (올바른 접근):
    Enum 생성부를 _create_enum_if_not_exists() 헬퍼로 교체.
    PL/pgSQL: DO $$ BEGIN CREATE TYPE ... EXCEPTION WHEN duplicate_object THEN null; END $$
    → op.execute()로 원시 SQL을 직접 실행하므로 asyncpg wrapper 영향을 받지 않음.
    → duplicate_object 예외를 DB 레벨에서 잡아 idempotent하게 동작.
    op.create_table() 내부 sa.Enum() 전체를 postgresql.ENUM(create_type=False)으로 교체 (14개).

  추가 교훈:
    - sa.Enum과 postgresql.ENUM은 다르다.
      sa.Enum: SQLAlchemy 크로스-DB 추상화 타입. create_type 파라미터 없음.
      postgresql.ENUM: PostgreSQL 전용. create_type=False 지원.
    - 향후 모든 마이그레이션에서 이 패턴을 유지한다.

[오류 3] FastAPI 앱 시작 실패 — ImportError: email-validator is not installed

  발생 시점: Alembic 성공 후 uvicorn 시작 시 스키마 클래스 로딩 단계
  원인: pydantic v2에서 EmailStr 필드 타입을 사용하면 런타임에 email-validator 패키지가
        필요하다. pyproject.toml에 pydantic만 선언하고 email-validator를 누락했음.
  수정: pydantic[email]>=2.7.0, email-validator>=2.1.0 추가.

[오류 4] bcrypt/passlib 버전 충돌 — ValueError: password cannot be longer than 72 bytes

  발생 시점: /auth/register → hash_password() 호출 시 500 Internal Server Error
  로그 패턴:
    (trapped) error reading bcrypt version
    AttributeError: module 'bcrypt' has no attribute '__about__'
    ValueError: password cannot be longer than 72 bytes, truncate manually
  원인: passlib 1.7.x는 bcrypt 3.x 기준으로 작성됨. bcrypt 4.0에서 __about__ 모듈이
        제거됐고 내부 API가 바뀌어 passlib이 버전 감지에 실패하면서 ValueError를 던짐.
        pip은 별도 제약 없이 bcrypt 최신 버전(4.x)을 설치했음.
  수정: bcrypt>=3.2.0,<4.0.0 핀 추가.
  참고: passlib 2.x 또는 bcrypt 호환 래퍼가 안정화되면 제약 해제 검토.

수정한 파일
-----------
  apps/backend/pyproject.toml
    - build-backend: "setuptools.backends.legacy:build" → "setuptools.build_meta"
    - 의존성 추가: "pydantic[email]>=2.7.0", "email-validator>=2.1.0"
    - 의존성 추가: "bcrypt>=3.2.0,<4.0.0"

  apps/backend/Dockerfile.dev
    - RUN: pip install --upgrade pip "setuptools>=68" && mkdir -p app && pip install -e ".[dev]"

  apps/backend/alembic/versions/a1b2c3d4e5f6_initial_schema.py
    - _create_enum_if_not_exists() 헬퍼 추가 (PL/pgSQL 방식)
    - op.create_table() 내 sa.Enum() 14개 모두 postgresql.ENUM(create_type=False)으로 교체

  infra/redis/redis.conf
    - requirepass devredis123 설정

설계 결정 사항
--------------
  Enum 생성 원칙: op.create_table() 내 열 정의에서는 postgresql.ENUM(create_type=False),
    별도 _create_enum_if_not_exists() 함수로 PL/pgSQL 방식 선행 생성.
    향후 마이그레이션 추가 시에도 동일 패턴 사용.
  bcrypt 버전 고정: <4.0.0 — passlib 2.x 출시 또는 bcrypt 호환 래퍼 도입 전까지 유지.

검증 방법 및 결과
-----------------
  docker compose ps: lookflex-postgres (healthy), lookflex-redis (healthy),
                    lookflex-backend (Up, no restart)
  GET http://localhost:8000/api/v1/health → {"status":"ok","version":"0.1.0"}
  POST http://localhost:8000/api/v1/auth/register
    payload: {"email":"test@example.com","name":"Test User","password":"TestPass1!","requested_role":"EDITOR"}
    response: {"success":true,"data":{"message":"이메일 인증 코드가 발송되었습니다.","email":"test@example.com"},"error":null}
  컨테이너 로그: [EMAIL - SMTP 미설정] to=test@example.com | subject=[LookFlex] 이메일 인증 코드
    → SMTP 미설정 시 콘솔 로그 폴백 정상 동작 확인

다음 단계 (예정)
----------------
  1. feature/users 브랜치에서 Users / Groups API 구현
  2. apps/frontend/ Next.js 스캐폴딩
  3. SMTP 설정 후 실 이메일 발송 테스트

================================================================================
[2026-02-28] testing.md 오탈자 수정 — psql 접속 유저명
================================================================================

배경
----
docs/testing.md 작성 후 실제 psql 접속 시도 중 오류 발생:
  psql: error: FATAL: role "lookflex" does not exist

원인
----
.env 파일의 POSTGRES_USER 값은 lookflex_user인데,
testing.md 전체에 걸쳐 -U lookflex 로 잘못 기재되어 있었다.
총 6곳: 3.5절 DB 직접 삽입, 3.8절 DB 확인, 5절 DB 상태 직접 확인 (4개 쿼리).

수정
----
  sed -i '' 's/-U lookflex -d lookflex/-U lookflex_user -d lookflex/g' docs/testing.md
  → 6곳 일괄 수정

재발 방지
---------
  접속 명령 작성 시 반드시 .env의 POSTGRES_USER 값(lookflex_user)을 참조할 것.

================================================================================
[2026-03-01] Auth 플로우 UI 중심 재설계 및 가이드라인 정비
================================================================================

배경
----
실제 테스트를 통해 Auth API 개선이 필요함을 확인했다.
기존 플로우에서는 /register 호출 시 먼저 RegisterRequest DB 레코드가 생성된 후
OTP가 발송됐는데, 이는 UI 흐름과 반대다.
일반적인 회원가입 UI는 이메일 입력창에서 인증 코드를 먼저 받아 "인증 완료" 상태로
폼 제출 버튼이 활성화된 뒤 나머지 정보를 입력한다.

변경 사항 요약
--------------
1. docs/ai-guidelines.md 신규 생성
  - 다른 프로젝트의 ai-guidelines.md를 이 프로젝트에 맞게 재작성
  - 버전 관리, 커밋 규칙, 브랜치 전략, 문서 작성 규칙, 기술 스택 포함
  - 테스트 파일 경로 규칙: docs/tests/{순번}-{도메인}.md

2. Auth 플로우 UI 중심 재설계 (0.1.0 → 0.1.1)
  변경 전 플로우:
    POST /register (DB 기록 생성 + OTP 발송)
    → POST /verify-email (OTP 검증 + DB email_verified_at 기록)
  변경 후 플로우:
    POST /send-verification (Redis OTP 저장만, DB 없음)
    → POST /verify-email (OTP 검증, Redis email_verified:{email} 저장, 30분 TTL)
    → POST /register (Redis 인증 여부 확인 후 RegisterRequest 생성, email_verified_at 즉시 기록)

3. 신규/수정 파일
  app/core/redis.py          — email_verified_key(email) 헬퍼 추가
  app/schemas/auth.py        — SendVerificationRequest 스키마 추가
  app/services/email_service.py — send_otp_email(to, code, name="사용자") name 선택적으로 변경
  app/services/auth_service.py  — send_verification 메서드 신규,
                                  verify_email DB 의존성 제거 (Redis만),
                                  register 인증 확인 로직 추가,
                                  resend_code DB 의존성 제거
  app/api/v1/auth.py         — POST /send-verification 엔드포인트 추가
  apps/backend/pyproject.toml, app/main.py — 버전 0.1.0 → 0.1.1
  docs/api.md                — §1 Auth 재구성: 1.1~1.11 (기존 10개 → 11개 엔드포인트)
  docs/tests/01-auth.md      — 새 플로우 반영 (3.1 send-verification 추가, 섹션 번호 조정)

4. docs/tests/ 경로 표준화
  기존 docs/testing.md → 사용자가 docs/tests/01-auth.md로 이동 완료

설계 결정 사항
--------------
  Redis 키 분리:
    otp:{email}           — OTP 코드 (10분)
    email_verified:{email} — 인증 완료 플래그 (30분, 폼 작성 여유 시간)
  이유: OTP 검증 완료 직후 OTP 키를 삭제하고 별도 verified 키를 생성함으로써
    중복 인증 시도를 차단하고, 폼 제출 전 verified 상태를 명확히 분리한다.
  resend-code: DB 없이 Redis OTP만 덮어쓰기 (이전 OTP 자동 무효화)
  RegisterRequest.email_verified_at: /register 호출 시점에 즉시 기록
    (별도 /verify-email 시점이 아님)

다음 단계 (예정)
----------------
  1. feature/auth 완료 처리: dev → main 머지, feature 브랜치 삭제
  2. feature/users 브랜치에서 Users / Groups API 구현

================================================================================
[2026-03-01] Docker 포트 관리 개선 및 Redis URL 컴포넌트 분리
================================================================================

배경
----
로컬에서 6379 포트가 이미 다른 프로세스에 의해 사용 중이어서 충돌 방지가 필요했다.
동시에 docker-compose에서 사용하는 포트들을 환경변수로 오버라이드할 수 있는 구조로
개선했다.

변경 사항
---------
1. docker-compose.dev.yml — 서비스 포트를 환경변수 기본값으로 노출
  ${POSTGRES_PORT:-5432}:5432
  ${REDIS_PORT:-6379}:6379    ← 호스트 포트만 변경, 컨테이너 내부는 항상 6379
  ${BACKEND_PORT:-8000}:8000
  ${FRONTEND_PORT:-3000}:3000

2. docker-compose.yml
  nginx: ${NGINX_HTTP_PORT:-80}:80

3. config.py — REDIS_URL 컴포넌트 분리 (model_validator 사용)
  REDIS_URL이 비어 있으면 REDIS_HOST / REDIS_PORT / REDIS_PASSWORD / REDIS_DB 로 조합
  Docker에서는 REDIS_URL을 직접 주입 → validator 건너뜀
  로컬에서는 .env의 REDIS_PORT 값을 읽어 유연하게 적용

4. .env.example — Redis 컴포넌트 변수 및 포트 오버라이드 섹션 참고용 추가
  REDIS_PASSWORD, REDIS_HOST, REDIS_PORT, REDIS_DB, REDIS_URL 주석 처리로 안내
  포트 오버라이드: POSTGRES_PORT, REDIS_PORT, BACKEND_PORT, FRONTEND_PORT, NGINX_HTTP_PORT

5. docs/infra.md — Redis 포트 관련 기술 내용 갱신

설계 결정 사항
--------------
  컨테이너 내부 Redis 포트는 항상 6379 (redis.conf port 설정 없음).
  호스트 노출 포트는 .env의 REDIS_PORT 또는 docker-compose 기본값으로 제어.
  .env.example에는 포트 값을 직접 명시하지 않음 (docker-compose 기본값으로 충분).
